{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(os.getcwd())\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "import math\n",
    "import scipy\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set(palette=\"bright\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "from sklearn import linear_model\n",
    "from cycler import cycler\n",
    "from celluloid import Camera\n",
    "from IPython.display import HTML\n",
    "\n",
    "import importlib\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "from tslib.src import tsUtils\n",
    "from tslib.tests import testdata\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, AffinityPropagation, DBSCAN #For clustering\n",
    "from sklearn.mixture import GaussianMixture #For GMM clustering\n",
    "from filter_data import *\n",
    "from load_and_clean import *\n",
    "import hdbscan\n",
    "import plotly.figure_factory as ff\n",
    "%matplotlib inline\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#update_data()\n",
    "\n",
    "us = load_clean('NYTimes US')\n",
    "uscases, usdeaths, usstates = load_clean('NYTimes states')\n",
    "uscounties_cases, uscounties_deaths, uscounties = load_clean('NYTimes counties')\n",
    "global_cases, global_deaths = load_clean('JHU global')\n",
    "us_covid_jhu_cases, us_covid_jhu_deaths = load_clean('JHU US')\n",
    "mobility_data_apple, mobility_data_google, google_social = load_clean('mobility')\n",
    "sd_data = load_clean('IHME intervention')\n",
    "all_population, us_population, usstates_population, uscounties_population = load_clean('population')\n",
    "\n",
    "uscases_pop_adjusted, usdeaths_pop_adjusted = create_population_adjusted_data(uscases, all_population), \\\n",
    "                                    create_population_adjusted_data(usdeaths, all_population, show_exception = True)\n",
    "global_cases_pop_adjusted, global_deaths_pop_adjusted = create_population_adjusted_data(global_cases, all_population), \\\n",
    "                                    create_population_adjusted_data(global_deaths, all_population, show_exception = True)\n",
    "\n",
    "uscounties_cases_pop_adjusted = create_population_adjusted_data(uscounties_cases, all_population, show_exception = True, county = True)\n",
    "uscounties_deaths_pop_adjusted = create_population_adjusted_data(uscounties_deaths, all_population, county = True)\n",
    "\n",
    "state_reopen = load_clean('state reopen')\n",
    "\n",
    "CTP = load_clean('CTP states')\n",
    "CTP_pop_adjusted = {name: create_population_adjusted_data(CTP[name], all_population) for name in CTP}\n",
    "\n",
    "#fips_df = pd.read_csv(\"../COVID/COVID-19/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter data (this part might be overlapping some cells, but it should contain most of the varilables that are analyzed. )\n",
    "# This part might be to split and explain\n",
    "# This part might be to split and explain\n",
    "t = 7\n",
    "column = list(mobility_data_google.columns).index('retail_and_recreation_percent_change_from_baseline')\n",
    "global_deaths_filtered = create_filtered_data(global_deaths, 500 )\n",
    "#the last column of social distancing dataset is the last social distancing measure used by a location\n",
    "educational_distancing = get_social_distancing(sd_data, sd_data.columns[-1])\n",
    "\n",
    "all_data = pd.concat([global_deaths, usdeaths, uscounties_deaths], axis=1)  \n",
    "all_data_daily = create_rolling_data(all_data, t)\n",
    "\n",
    "all_data_cases = pd.concat([global_cases, uscases, uscounties_cases], axis=1) \n",
    "all_data_cases_daily = create_rolling_data(all_data_cases, t)\n",
    "\n",
    "all_cases_data_pop = pd.concat([uscases_pop_adjusted,global_cases_pop_adjusted, uscounties_cases_pop_adjusted], axis = 1)\n",
    "all_cases_data_pop_daily = create_rolling_data(all_cases_data_pop, t)\n",
    "\n",
    "all_death_data_pop = pd.concat([usdeaths_pop_adjusted,global_deaths_pop_adjusted, uscounties_deaths_pop_adjusted], axis = 1)\n",
    "all_death_data_pop_daily = create_rolling_data(all_death_data_pop, t)\n",
    "\n",
    "_, daily_global, intervention_date_global = create_intervention_adjusted_data(global_deaths, educational_distancing, t)\n",
    "_, daily_us, intervention_date_us = create_intervention_adjusted_data(usdeaths, educational_distancing, t)\n",
    "_, daily_uscounties, intervention_date_uscounties = create_intervention_adjusted_data(uscounties_deaths, educational_distancing, t)\n",
    "\n",
    "cases_intervention_adjusted, cases_intervention_adjusted_daily, intervention_date_case = create_intervention_adjusted_data(all_data_cases, educational_distancing, t)\n",
    "deaths_intervention_adjusted, deaths_intervention_adjusted_daily, intervention_date_death = create_intervention_adjusted_data(all_data, educational_distancing, t)\n",
    "#deaths_intervention_adjusted_google, deaths_intervention_adjusted_daily_google, _ = create_intervention_adjusted_data(all_data, google_social, t)\n",
    "\n",
    "all_cases_data_pop_adjusted, all_cases_data_pop_adjusted_daily, _ = create_intervention_adjusted_data(all_cases_data_pop, educational_distancing, t)\n",
    "all_death_data_pop_adjusted, all_death_data_pop_adjusted_daily, _ = create_intervention_adjusted_data(all_death_data_pop, educational_distancing, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data, fips = load_clean('temperature')\n",
    "post_memo = temp_data.loc['2020-05-25':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 12))\n",
    "plt.scatter(post_memo.mean(), post_memo.std())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict, features = cluster_time_series(post_memo, min_cluster_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.drop_duplicates(pd.merge(features['cluster'].reset_index(), fips, \n",
    "                              how = 'right', on = ['county_state']))\n",
    "group = df['fips']\n",
    "values = df['cluster']\n",
    "fig = ff.create_choropleth(fips=group, values=values)\n",
    "fig.layout.template = None\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "dfplot=all_data_cases_daily\n",
    "i=0\n",
    "for key in feature_dict:\n",
    "    group = feature_dict[key]\n",
    "    temp = []\n",
    "    for county in group:\n",
    "        if county in dfplot.columns:\n",
    "            temp.append(county)\n",
    "    (1000000*dfplot[temp].sum(axis=1)/(all_population[all_population.index.isin(temp)].value.sum())).plot(label = key)\n",
    "    #(1000000*dfplot[temp].sum(axis=1)/(all_population[all_population.index.isin(temp)].value.sum())).plot(label=group_labels[i])\n",
    "    plt.xticks(rotation=45), plt.ylabel('Moving Average Daily Cases'), plt.title('Cases'), plt.legend()\n",
    "    i=i+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-means\n",
    "feature_dict, features = cluster_time_series(post_memo, cluster_method = 'kmeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.drop_duplicates(pd.merge(features['cluster'].reset_index(), fips, \n",
    "                              how = 'right', on = ['county_state']))\n",
    "group = df['fips']\n",
    "values = df['cluster']\n",
    "fig = ff.create_choropleth(fips=group, values=values)\n",
    "fig.layout.template = None\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "dfplot=all_data_cases_daily\n",
    "i=0\n",
    "for key in feature_dict:\n",
    "    group = feature_dict[key]\n",
    "    temp = []\n",
    "    for county in group:\n",
    "        if county in dfplot.columns:\n",
    "            temp.append(county)\n",
    "    (1000000*dfplot[temp].sum(axis=1)/(all_population[all_population.index.isin(temp)].value.sum())).plot(label = key)\n",
    "    #(1000000*dfplot[temp].sum(axis=1)/(all_population[all_population.index.isin(temp)].value.sum())).plot(label=group_labels[i])\n",
    "    plt.xticks(rotation=45), plt.ylabel('Moving Average Daily Cases'), plt.title('Cases'), plt.legend()\n",
    "    i=i+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict, features = cluster_time_series(post_memo, cluster_method = 'AgglomerativeClustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.drop_duplicates(pd.merge(features['cluster'].reset_index(), fips, \n",
    "                              how = 'right', on = ['county_state']))\n",
    "group = df['fips']\n",
    "values = df['cluster']\n",
    "fig = ff.create_choropleth(fips=group, values=values)\n",
    "fig.layout.template = None\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "dfplot=all_data_cases_daily\n",
    "i=0\n",
    "for key in feature_dict:\n",
    "    group = feature_dict[key]\n",
    "    temp = []\n",
    "    for county in group:\n",
    "        if county in dfplot.columns:\n",
    "            temp.append(county)\n",
    "    (1000000*dfplot[temp].sum(axis=1)/(all_population[all_population.index.isin(temp)].value.sum())).plot(label = key)\n",
    "    #(1000000*dfplot[temp].sum(axis=1)/(all_population[all_population.index.isin(temp)].value.sum())).plot(label=group_labels[i])\n",
    "    plt.xticks(rotation=45), plt.ylabel('Moving Average Daily Cases'), plt.title('Cases'), plt.legend()\n",
    "    i=i+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in feature_dict:\n",
    "    feature_dict[key] = list(feature_dict[key])\n",
    "np.save('temp_cluster.npy', feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
